{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spark_with_GoogleGolab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IVMcVQc2250m"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"dwqKU-PhhC58"},"source":["##Apache Spark with Google Colab\n","\n","\n","Setting up  Spark 2.4.7 with all dependencies on google colab. \n","\n","* Installing Java in the Google Colaboratory\n","* Setting up Spark 2.4.7  in the Google Colaboratory\n","* A test example\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2COZzvqcf-Pg"},"source":["# Setting up Spark 2.4.7 the Google Colaboratory\n","\n","This notebook comprises the instructions to run pyspark on google Colab. \n","\n","We will install the following OS tools \n","\n","* Java 8\n","* spark-2.4.7\n","* Hadoop2.7\n","* [Findspark](https://github.com/minrk/findspark)\n","\n","\n","> Make sure the spark-version you are downloading is availbale on target link\n","\n"]},{"cell_type":"code","metadata":{"id":"3MZdDu9LhLwN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606835831475,"user_tz":-120,"elapsed":36554,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}},"outputId":"9270d06e-fd49-46b1-8ccb-a6890d920c6e"},"source":["import time\n","\n","Start=time.time()\n","# Download and install tools \n","\n","# Install Java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Download and Install Spark\n","!wget  -q http://apache.osuosl.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n","\n","# Install findspark\n","!pip install -q findspark\n","\n","print(f\"\\nIt took {(time.time()-Start)} seconds to install all dependencies for spark to run on Google Colab. \\n\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\n","It took 35.79347634315491 seconds to install all dependencies for spark to run on Google Colab. \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sit9TX0chlNF","executionInfo":{"status":"ok","timestamp":1606836202839,"user_tz":-120,"elapsed":2660,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}}},"source":["# Set environment variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"da7M2Wi1jC1c"},"source":["## Spark Installation test\n","Lets test the installation of spark in our google colab environment. "]},{"cell_type":"code","metadata":{"id":"OIafpxrv5yig","executionInfo":{"status":"ok","timestamp":1606836335150,"user_tz":-120,"elapsed":1373,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}}},"source":["import findspark\n","findspark.init()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AO2xiF795z4y"},"source":[""]},{"cell_type":"code","metadata":{"id":"sbQm8jbm5zZa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4wlH2fq7BJr","executionInfo":{"status":"ok","timestamp":1606836627570,"user_tz":-120,"elapsed":1802,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}},"outputId":"b19f08fa-3a8f-4d5b-b635-61ebb7a7dd29"},"source":["{\"Column1\": np.random.randint(1,100), \n","                             \"Column2\":np.random.randint(24,35), \n","                             \"Column3\":np.random.random(),\n","                             \"Name\":str(np.random.choice(NameList)),\n","                             }"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Column1': 60, 'Column2': 32, 'Column3': 0.2051885238744462, 'Name': 'Salem'}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Y18KVg34jkXj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606836575352,"user_tz":-120,"elapsed":11264,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}},"outputId":"bfd72cee-5b54-4b9b-ff37-01c829c87fa8"},"source":["import findspark\n","import numpy as np\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","\n","# Test the spark \n","NameList = ['Ahmad', 'Salem', 'Noor', 'Heba']\n","\n","NumberOfSamples=int(1000)\n","\n","df = spark.createDataFrame([{\"Column1\": np.random.randint(1,100), \n","                             \"Column2\":np.random.randint(24,35), \n","                             \"Column3\":np.random.random(),\n","                             \"Name\":str(np.random.choice(NameList)),\n","                             }\n","                              for i in range(NumberOfSamples)])\n","\n","df.show(3, False)\n","\n","#spark.stop()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n","  warnings.warn(\"inferring schema from dict is deprecated,\"\n"],"name":"stderr"},{"output_type":"stream","text":["+-------+-------+-------------------+-----+\n","|Column1|Column2|Column3            |Name |\n","+-------+-------+-------------------+-----+\n","|30     |30     |0.7614356383694527 |Heba |\n","|61     |33     |0.38477270624534354|Ahmad|\n","|33     |28     |0.21574509717802604|Heba |\n","+-------+-------+-------------------+-----+\n","only showing top 3 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"coa-Lp2Yyc2V"},"source":["###Check Schema [Property]"]},{"cell_type":"code","metadata":{"id":"0TiyN-6tyRbR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0800fac5-3a9b-48ed-d56f-2a27655008c3"},"source":["df.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- Column1: long (nullable = true)\n"," |-- Column2: long (nullable = true)\n"," |-- Column3: double (nullable = true)\n"," |-- Name: string (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZd0mqk6yRzq"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPBZCSVLyRhQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPNhJYhnyRI_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pe6Mlcs29vX-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606836765143,"user_tz":-120,"elapsed":1298,"user":{"displayName":"Ibrahim Abu Alhaol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRvrebxMDZgnHVVgf2jggVAk9E6ufnpjzPPcXJ=s64","userId":"00373072729262931595"}},"outputId":"f016c065-a303-4a34-943f-a9f8a9a18303"},"source":["# Check the pyspark version\n","import pyspark\n","print(pyspark.__version__)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2.4.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VjUld8S6bRHz"},"source":["# Conclusions\n","\n","In this notebook, we learned\n","\n","* Installing spark 2.4.7 in Google Colab\n","* Running some spark methods without cost \n"]},{"cell_type":"code","metadata":{"id":"At0dtijv-aBn"},"source":[""],"execution_count":null,"outputs":[]}]}